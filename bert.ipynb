{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "976e849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac92e70-da5b-4c20-bf7d-0fdbb64c8d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for KO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['KO']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty data returned for KO, retrying...\n",
      "Waiting 5 seconds before retry 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['KO']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty data returned for KO, retrying...\n",
      "Waiting 5 seconds before retry 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['KO']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty data returned for KO, retrying...\n",
      "Waiting 5 seconds before retry 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['KO']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty data returned for KO, retrying...\n",
      "Waiting 5 seconds before retry 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['KO']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty data returned for KO, retrying...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to download data for KO after 5 attempts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# example data\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPEP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2022-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# prepare data for BERT\u001b[39;00m\n\u001b[0;32m     62\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpread_Change\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpread\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdiff()\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[18], line 40\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(ticker1, ticker2, start_date, end_date)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Download data for both tickers with retry logic\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m data1 \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m data2 \u001b[38;5;241m=\u001b[39m download_retry(ticker2)\n",
      "Cell \u001b[1;32mIn[18], line 36\u001b[0m, in \u001b[0;36mload_data.<locals>.download_retry\u001b[1;34m(ticker, max_retries, delay)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds before retry \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempts\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(delay)\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to download data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attempts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to download data for KO after 5 attempts"
     ]
    }
   ],
   "source": [
    "\n",
    "# import the bert tokenizer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# load financial data\n",
    "def load_data(ticker1, ticker2, start_date, end_date):\n",
    "    # Helper function to retry downloads\n",
    "    def download_retry(ticker, max_retries=5, delay=5):\n",
    "        attempts = 0\n",
    "        while attempts < max_retries:\n",
    "            try:\n",
    "                data = yf.download(ticker, start=start_date, end=end_date)\n",
    "                if not data.empty:\n",
    "                    return data\n",
    "                else:\n",
    "                    print(f\"Empty data returned for {ticker}, retrying...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {ticker}: {e}\")\n",
    "            \n",
    "            attempts += 1\n",
    "            if attempts < max_retries:\n",
    "                print(f\"Waiting {delay} seconds before retry {attempts+1}/{max_retries}\")\n",
    "                time.sleep(delay)\n",
    "        \n",
    "        raise ValueError(f\"Failed to download data for {ticker} after {max_retries} attempts\")\n",
    "    \n",
    "    # download the data retrying if necessary\n",
    "    print(f\"Downloading data for {ticker1}...\")\n",
    "    data1 = download_retry(ticker1)\n",
    "    print(f\"Downloading data for {ticker2}...\")\n",
    "    data2 = download_retry(ticker2)\n",
    "    \n",
    "    # Align the data by date\n",
    "    common_dates = data1.index.intersection(data2.index)\n",
    "    data1 = data1.loc[common_dates]\n",
    "    data2 = data2.loc[common_dates]\n",
    "    \n",
    "    # Combine the data into a single DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'Date': common_dates,\n",
    "        'Spread': data1['Adj Close'] - data2['Adj Close']\n",
    "    }).set_index('Date')\n",
    "    \n",
    "    print(f\"Successfully loaded spread data with {len(data)} rows\")\n",
    "    return data\n",
    "\n",
    "# example data\n",
    "data = load_data('KO', 'PEP', '2022-01-01', '2023-01-01')\n",
    "\n",
    "# prepare data for BERT\n",
    "data[\"Spread_Change\"] = data[\"Spread\"].diff().fillna(0)\n",
    "texts = data[\"Spread_Change\"].astype(str).tolist()\n",
    "labels = (data[\"Spread_Change\"] > 0).astype(int).tolist() # 1 for positive change, 0 for negative change\n",
    "\n",
    "# tokenize and encode the data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# loading the BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# fine tune the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5) # learning rate\n",
    "model.train()\n",
    "\n",
    "for epoch in range(3): # number of epochs\n",
    "    optimizer.zero_grad() # clear previous gradients\n",
    "    outputs = model(**inputs, labels=labels) # forward pass\n",
    "    loss = outputs.loss # compute the loss\n",
    "    loss.backward() # backpropagation\n",
    "    optimizer.step() # update the weights\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\") # print the loss\n",
    "\n",
    "# Generate Predictions\n",
    "model.eval() # set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs) # forward pass\n",
    "    predictions = torch.argmax(outputs.logits, dim=1) # get the predicted labels\n",
    "\n",
    "# evaluate performance\n",
    "mse = mean_squared_error(labels, predictions)\n",
    "r2 = r2_score(labels, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
