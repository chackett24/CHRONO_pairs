{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55b7c50",
   "metadata": {},
   "source": [
    "## In this file, we try to predict spread\n",
    "We are using BERT model to predict the spread of the assets with the following steps:\n",
    "- Using spreads.csv -- has columns: 'Date', 'Ticker Pair', 'Spread', and 'Return'\n",
    "- Making a texts column takin  \n",
    "\n",
    "Desired output format: 'Date', 'Ticker Pair', 'Spread', 'Return'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976e849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec691c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Ticker_Pair",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Spread",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tick1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tick2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "texts",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7785199d-8b69-433a-b769-c36279c06905",
       "rows": [
        [
         "0",
         "2016-01-10 00:00:00",
         "AAPL-MSFT",
         "-0.5440554868481",
         null,
         "AAPL",
         "MSFT",
         "The spread for AAPL-MSFT on 2016-01-10 is -0.5440554868481"
        ],
        [
         "1",
         "2016-01-17 00:00:00",
         "AAPL-MSFT",
         "-0.1658578548936782",
         "0.02736004392201",
         "AAPL",
         "MSFT",
         "The spread for AAPL-MSFT on 2016-01-17 is -0.1658578548936782"
        ],
        [
         "2",
         "2016-01-24 00:00:00",
         "AAPL-MSFT",
         "0.0805789854929333",
         "0.0186723950192431",
         "AAPL",
         "MSFT",
         "The spread for AAPL-MSFT on 2016-01-24 is 0.0805789854929333"
        ],
        [
         "3",
         "2016-01-31 00:00:00",
         "AAPL-MSFT",
         "-1.1925950018254965",
         "-0.0937761899072257",
         "AAPL",
         "MSFT",
         "The spread for AAPL-MSFT on 2016-01-31 is -1.1925950018254965"
        ],
        [
         "4",
         "2016-02-07 00:00:00",
         "AAPL-MSFT",
         "-0.312256735178449",
         "0.0606238217795922",
         "AAPL",
         "MSFT",
         "The spread for AAPL-MSFT on 2016-02-07 is -0.312256735178449"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker_Pair</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Return</th>\n",
       "      <th>tick1</th>\n",
       "      <th>tick2</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>AAPL-MSFT</td>\n",
       "      <td>-0.544055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>The spread for AAPL-MSFT on 2016-01-10 is -0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>AAPL-MSFT</td>\n",
       "      <td>-0.165858</td>\n",
       "      <td>0.027360</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>The spread for AAPL-MSFT on 2016-01-17 is -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>AAPL-MSFT</td>\n",
       "      <td>0.080579</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>The spread for AAPL-MSFT on 2016-01-24 is 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>AAPL-MSFT</td>\n",
       "      <td>-1.192595</td>\n",
       "      <td>-0.093776</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>The spread for AAPL-MSFT on 2016-01-31 is -1.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-07</td>\n",
       "      <td>AAPL-MSFT</td>\n",
       "      <td>-0.312257</td>\n",
       "      <td>0.060624</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>The spread for AAPL-MSFT on 2016-02-07 is -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker_Pair    Spread    Return tick1 tick2  \\\n",
       "0 2016-01-10   AAPL-MSFT -0.544055       NaN  AAPL  MSFT   \n",
       "1 2016-01-17   AAPL-MSFT -0.165858  0.027360  AAPL  MSFT   \n",
       "2 2016-01-24   AAPL-MSFT  0.080579  0.018672  AAPL  MSFT   \n",
       "3 2016-01-31   AAPL-MSFT -1.192595 -0.093776  AAPL  MSFT   \n",
       "4 2016-02-07   AAPL-MSFT -0.312257  0.060624  AAPL  MSFT   \n",
       "\n",
       "                                               texts  \n",
       "0  The spread for AAPL-MSFT on 2016-01-10 is -0.5...  \n",
       "1  The spread for AAPL-MSFT on 2016-01-17 is -0.1...  \n",
       "2  The spread for AAPL-MSFT on 2016-01-24 is 0.08...  \n",
       "3  The spread for AAPL-MSFT on 2016-01-31 is -1.1...  \n",
       "4  The spread for AAPL-MSFT on 2016-02-07 is -0.3...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load financial data -- Note we have the following columns: Date, Ticker Pair, BERT Spread, BERT Position\n",
    "data = pd.read_csv('outputs/spreads_weekly_large.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.rename(columns={\"Ticker Pair\": \"Ticker_Pair\"}, inplace=True)\n",
    "data[[\"tick1\", \"tick2\"]] = data[\"Ticker_Pair\"].str.split(\"-\", expand=True)\n",
    "# create text description for BERT to process\n",
    "data['texts'] = [f\"The spread for {row['Ticker_Pair']} on {row['Date'].strftime('%Y-%m-%d')} is {row['Spread']}\" for index, row in data.iterrows()]\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ac92e70-da5b-4c20-bf7d-0fdbb64c8d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded: 1560 rows\n",
      "Spread distribution -1.7949530750627218e-13, 1560.0000000000002\n",
      "Train Size: 1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForRegression were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['regressor.1.bias', 'regressor.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 0.352624\n",
      "Epoch 2/5, Average Loss: 0.117978\n",
      "Epoch 3/5, Average Loss: 0.102877\n",
      "Epoch 4/5, Average Loss: 0.062034\n",
      "Epoch 5/5, Average Loss: 0.043366\n"
     ]
    }
   ],
   "source": [
    "# import the bert tokenizer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "texts = data['texts'].values\n",
    "spread = data['Spread'].values\n",
    "print(f'Data Loaded: {len(data)} rows')\n",
    "print(f'Spread distribution {sum(spread)}, {len(spread) - sum(spread)}')\n",
    "\n",
    "\n",
    "## Change this for the actual task -- we will just train and predict on unseen data\n",
    "# create the train/test split for regression task\n",
    "# train_texts, test_texts, train_spreads, test_spreads = train_test_split(\n",
    "#     texts, spread, test_size=0.0, random_state=42)\n",
    "train_texts = texts\n",
    "train_spreads = spread\n",
    "print(f'Train Size: {len(train_texts)}')\n",
    "\n",
    "\n",
    "# tokenize and encode the data using a pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenize training data\n",
    "train_encodings = tokenizer(list(train_texts), padding=True, truncation=True, return_tensors='pt', max_length=1000)\n",
    "\n",
    "## This will not be necessary\n",
    "# tokenize test data\n",
    "# test_encodings = tokenizer(list(test_texts), padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "# Convert spread values to float tensors for regression\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], \n",
    "                            train_encodings['attention_mask'], \n",
    "                            torch.tensor(train_spreads, dtype=torch.float32))\n",
    "# test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_spreads, dtype=torch.float32))\n",
    "\n",
    "# create data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# loading the BERT model\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "\n",
    "class BertForRegression(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(config.hidden_dropout_prob),  # Fixed: torch.nn.Dropout instead of torch.nnDropout\n",
    "            torch.nn.Linear(config.hidden_size, 1)  # Output layer for regression\n",
    "        )\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, **kwargs):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,  \n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        return self.regressor(pooled_output)\n",
    "\n",
    "# loading the BERT model for regression (num_labels=1 for regression)\n",
    "model = BertForRegression.from_pretrained('bert-base-uncased', \n",
    "                                         config=BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1).config)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# fine tune the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5) # higher learning rate for regression\n",
    "\n",
    "# Using MSE for loss regression\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# epochs means one complete pass through the entire training dataset. \n",
    "# epoch 1: the model sees all training data once and makes initial adjustments\n",
    "# epoch 2: the model sees the data again, learns from its previous mistakes, and makes further adjustments\n",
    "# epoch 3: the model sees the data a third time, refines its understanding, and makes final adjustments\n",
    "# In this case, we will use 3 epochs for training.\n",
    "num_epochs = 5 # increased from 3 for regression task \n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, batch_spreads = [b.to(device) for b in batch]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        # Reshape outputs to match target shape\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        \n",
    "        # Calculate regression loss\n",
    "        loss = loss_fn(outputs, batch_spreads)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {total_loss / len(train_loader):.6f}\")\n",
    "\n",
    "# # saving the model so that we don't have to retrain it every time\n",
    "# model_save_path = 'outputs/bert_regression_model'\n",
    "# model.save_pretrained(model_save_path)\n",
    "# tokenizer.save_pretrained(model_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f3f0e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation\n",
    "# model.eval()\n",
    "# all_preds = []\n",
    "# all_spreads = []\n",
    "# eval_loss = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in test_loader:\n",
    "#         input_ids, attention_mask, batch_spreads = [b.to(device) for b in batch]\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask)\n",
    "#         outputs = outputs.squeeze(-1)\n",
    "        \n",
    "#         # Calculate loss\n",
    "#         loss = loss_fn(outputs, batch_spreads)\n",
    "#         eval_loss += loss.item()\n",
    "        \n",
    "#         all_preds.extend(outputs.cpu().numpy())\n",
    "#         all_spreads.extend(batch_spreads.cpu().numpy())\n",
    "\n",
    "# print(f\"Evaluation Loss: {eval_loss / len(test_loader):.6f}\")\n",
    "\n",
    "# # Calculate regression metrics\n",
    "# mse = mean_squared_error(all_spreads, all_preds)\n",
    "# mae = mean_absolute_error(all_spreads, all_preds)\n",
    "# r2 = r2_score(all_spreads, all_preds)\n",
    "\n",
    "# print(f\"Mean Squared Error: {mse:.6f}\")\n",
    "# print(f\"Mean Absolute Error: {mae:.6f}\")\n",
    "# print(f\"R^2 Score: {r2:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "# # Visualize predictions vs actual values\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# # Plot sample of predictions (first 100 points)\n",
    "# sample_size = min(100, len(all_preds))\n",
    "# plt.scatter(range(sample_size), all_spreads[:sample_size], color='blue', label='Actual')\n",
    "# plt.scatter(range(sample_size), all_preds[:sample_size], color='red', label='Predicted')\n",
    "# plt.title('BERT Spread Prediction: Actual vs Predicted')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Spread Value')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Plot correlation\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.scatter(all_spreads, all_preds, alpha=0.5)\n",
    "# plt.plot([min(all_spreads), max(all_spreads)], [min(all_spreads), max(all_spreads)], 'r--')\n",
    "# plt.xlabel('Actual Spread')\n",
    "# plt.ylabel('Predicted Spread')\n",
    "# plt.title('Correlation between Actual and Predicted Spreads')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cccb515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last date in training data: 2018-12-30 00:00:00\n",
      "Predictions for the following dates: DatetimeIndex(['2019-01-06', '2019-01-13', '2019-01-20', '2019-01-27',\n",
      "               '2019-02-03', '2019-02-10', '2019-02-17', '2019-02-24',\n",
      "               '2019-03-03', '2019-03-10', '2019-03-17', '2019-03-24',\n",
      "               '2019-03-31', '2019-04-07', '2019-04-14', '2019-04-21',\n",
      "               '2019-04-28', '2019-05-05', '2019-05-12', '2019-05-19',\n",
      "               '2019-05-26', '2019-06-02', '2019-06-09', '2019-06-16',\n",
      "               '2019-06-23', '2019-06-30', '2019-07-07', '2019-07-14',\n",
      "               '2019-07-21', '2019-07-28', '2019-08-04', '2019-08-11',\n",
      "               '2019-08-18', '2019-08-25', '2019-09-01', '2019-09-08',\n",
      "               '2019-09-15', '2019-09-22', '2019-09-29', '2019-10-06',\n",
      "               '2019-10-13', '2019-10-20', '2019-10-27', '2019-11-03',\n",
      "               '2019-11-10', '2019-11-17', '2019-11-24', '2019-12-01',\n",
      "               '2019-12-08', '2019-12-15', '2019-12-22', '2019-12-29'],\n",
      "              dtype='datetime64[ns]', freq='W-SUN')\n",
      "Found 10 unique ticker pairs\n",
      "\n",
      "Predictions head:\n",
      "          Date Ticker_Pair  BERT_Spread BERT_Position\n",
      "0   2019-01-06   AAPL-MSFT     0.214850           buy\n",
      "104 2019-01-06    AMD-NVDA     0.218491           buy\n",
      "364 2019-01-06  GOOGL-AAPL     0.224701           buy\n",
      "52  2019-01-06  GOOGL-META     0.227123           buy\n",
      "312 2019-01-06     JPM-BAC     0.229534           buy\n",
      "Saved 520 predictions to 'outputs/bert_spread_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# predict for the following dates: 1/1/2019 - 12/31/2019\n",
    "# Do monthly predictions for a year after the training data\n",
    "# input data set has weekly returns\n",
    "\n",
    "# getting the last date in the training data\n",
    "last_date = data['Date'].max()\n",
    "print(f'Last date in training data: {last_date}')\n",
    "\n",
    "# create a date range for the next year\n",
    "start_date = last_date + pd.DateOffset(days=1)  \n",
    "end_date = start_date + pd.DateOffset(years=1)  \n",
    "\n",
    "## change this line for the actual task -- weekly, monthly, yearly...\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='W')  # Weekly frequency\n",
    "\n",
    "print(f'Predictions for the following dates: {date_range}')\n",
    "\n",
    "# Get unique ticker pairs from the dataset\n",
    "ticker_pairs = data['Ticker_Pair'].unique()\n",
    "print(f'Found {len(ticker_pairs)} unique ticker pairs')\n",
    "\n",
    "# Create a DataFrame to store all predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# For each ticker pair, make predictions for all future dates\n",
    "for ticker_pair in ticker_pairs:\n",
    "    # Create predictions for each date\n",
    "    for prediction_date in date_range:\n",
    "        formatted_date = prediction_date.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Create input text in the same format as training data\n",
    "        # Using 0.0 as a placeholder\n",
    "        input_text = f\"The spread for {ticker_pair} on {formatted_date} is 0.0\"\n",
    "        \n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(\n",
    "            input_text, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='pt', \n",
    "            max_length=128\n",
    "        ).to(device)\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predicted_spread = outputs.squeeze().item()\n",
    "        \n",
    "        # Determine position based on predicted spread\n",
    "        # Positive spread typically indicates a buy signal (1), negative a sell signal (0)\n",
    "        position = 'buy' if predicted_spread > 0 else 'sell'\n",
    "        \n",
    "        # Add to predictions list\n",
    "        all_predictions.append({\n",
    "            'Date': prediction_date,\n",
    "            'Ticker_Pair': ticker_pair,\n",
    "            'BERT_Spread': predicted_spread,\n",
    "            'BERT_Position': position\n",
    "        })\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "predictions = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Sort by date and ticker pair\n",
    "predictions = predictions.sort_values(['Date', 'Ticker_Pair'])\n",
    "\n",
    "# Display the first few predictions\n",
    "print(\"\\nPredictions head:\")\n",
    "print(predictions.head())\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions.to_csv('outputs/bert_spread.csv', index=False)\n",
    "print(f\"Saved {len(predictions)} predictions to 'outputs/bert_spread_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bf47a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spread Analysis:\n",
      "Prediction Mean Spread:\n",
      "Ticker_Pair\n",
      "AAPL-MSFT     0.208537\n",
      "AMD-NVDA      0.213066\n",
      "GOOGL-AAPL    0.221356\n",
      "GOOGL-META    0.220569\n",
      "JPM-BAC       0.225258\n",
      "KO-PEP        0.285478\n",
      "META-NFLX     0.257731\n",
      "NFLX-DIS      0.282989\n",
      "TSLA-GM       0.213965\n",
      "TSLA-NVDA     0.202125\n",
      "Name: BERT_Spread, dtype: float64\n",
      "Original Mean Spread:\n",
      "Ticker_Pair\n",
      "AAPL-MSFT     5.750386e-16\n",
      "AMD-NVDA     -4.099285e-16\n",
      "GOOGL-AAPL   -2.490885e-17\n",
      "GOOGL-META    1.403436e-15\n",
      "JPM-BAC      -2.729298e-16\n",
      "KO-PEP       -2.072416e-15\n",
      "META-NFLX     9.109522e-17\n",
      "NFLX-DIS      1.665335e-16\n",
      "TSLA-GM      -1.708035e-17\n",
      "TSLA-NVDA    -2.005162e-16\n",
      "Name: Spread, dtype: float64\n",
      "Prediction Standard Deviation of Spread:\n",
      "Ticker_Pair\n",
      "AAPL-MSFT     0.014535\n",
      "AMD-NVDA      0.013082\n",
      "GOOGL-AAPL    0.015766\n",
      "GOOGL-META    0.015294\n",
      "JPM-BAC       0.013180\n",
      "KO-PEP        0.019324\n",
      "META-NFLX     0.014022\n",
      "NFLX-DIS      0.019214\n",
      "TSLA-GM       0.013983\n",
      "TSLA-NVDA     0.013133\n",
      "Name: BERT_Spread, dtype: float64\n",
      "Original Standard Deviation of Spread:\n",
      "Ticker_Pair\n",
      "AAPL-MSFT     1.0\n",
      "AMD-NVDA      1.0\n",
      "GOOGL-AAPL    1.0\n",
      "GOOGL-META    1.0\n",
      "JPM-BAC       1.0\n",
      "KO-PEP        1.0\n",
      "META-NFLX     1.0\n",
      "NFLX-DIS      1.0\n",
      "TSLA-GM       1.0\n",
      "TSLA-NVDA     1.0\n",
      "Name: Spread, dtype: float64\n",
      "Count of Predictions:\n",
      "Ticker_Pair\n",
      "AAPL-MSFT     52\n",
      "AMD-NVDA      52\n",
      "GOOGL-AAPL    52\n",
      "GOOGL-META    52\n",
      "JPM-BAC       52\n",
      "KO-PEP        52\n",
      "META-NFLX     52\n",
      "NFLX-DIS      52\n",
      "TSLA-GM       52\n",
      "TSLA-NVDA     52\n",
      "Name: BERT_Spread, dtype: int64\n",
      "Prediction Max Spread:\n",
      "Ticker_Pair\n",
      "AAPL-MSFT     0.238500\n",
      "AMD-NVDA      0.243965\n",
      "GOOGL-AAPL    0.250416\n",
      "GOOGL-META    0.250961\n",
      "JPM-BAC       0.250804\n",
      "KO-PEP        0.335900\n",
      "META-NFLX     0.294074\n",
      "NFLX-DIS      0.343639\n",
      "TSLA-GM       0.240420\n",
      "TSLA-NVDA     0.234802\n",
      "Name: BERT_Spread, dtype: float64\n",
      "Prediction Min Spread:\n",
      "Ticker_Pair\n",
      "AAPL-MSFT     0.184524\n",
      "AMD-NVDA      0.187328\n",
      "GOOGL-AAPL    0.189785\n",
      "GOOGL-META    0.191858\n",
      "JPM-BAC       0.196129\n",
      "KO-PEP        0.248073\n",
      "META-NFLX     0.230663\n",
      "NFLX-DIS      0.251191\n",
      "TSLA-GM       0.188513\n",
      "TSLA-NVDA     0.175786\n",
      "Name: BERT_Spread, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# making some analysis on the predictions using the predictions df\n",
    "spread_mean = predictions.groupby('Ticker_Pair')['BERT_Spread'].mean()\n",
    "spread_std = predictions.groupby('Ticker_Pair')['BERT_Spread'].std()\n",
    "spread_count = predictions.groupby('Ticker_Pair')['BERT_Spread'].count()\n",
    "spread_max = predictions.groupby('Ticker_Pair')['BERT_Spread'].max()\n",
    "spread_min = predictions.groupby('Ticker_Pair')['BERT_Spread'].min()\n",
    "\n",
    "print(\"\\nSpread Analysis:\")\n",
    "print(f\"Prediction Mean Spread:\\n{spread_mean}\")\n",
    "print(f\"Original Mean Spread:\\n{data.groupby('Ticker_Pair')['Spread'].mean()}\")\n",
    "print(f\"Prediction Standard Deviation of Spread:\\n{spread_std}\")\n",
    "print(f\"Original Standard Deviation of Spread:\\n{data.groupby('Ticker_Pair')['Spread'].std()}\")\n",
    "print(f\"Count of Predictions:\\n{spread_count}\")\n",
    "print(f\"Prediction Max Spread:\\n{spread_max}\")\n",
    "print(f\"Prediction Min Spread:\\n{spread_min}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
